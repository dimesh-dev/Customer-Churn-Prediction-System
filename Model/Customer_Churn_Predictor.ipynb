{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telco Customer Churn Prediction\n",
    "\n",
    "## Task 1: Exploratory Data Analysis (EDA)\n",
    "This notebook covers the step-by-step process of analyzing the Telco Customer Churn dataset, preprocessing the data, building classification models, and evaluating them.\n",
    "\n",
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Reproducibility for NN training\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Cleaning & Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'TotalCharges' is object but should be numeric. Coerce errors to NaN.\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing TotalCharges (usually very few)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove 'customerID' as it's not a feature\n",
    "if 'customerID' in df.columns:\n",
    "    df.drop(columns=['customerID'], inplace=True)\n",
    "\n",
    "print(\"New Shape after cleaning:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE CLEANED DATASET\n",
    "df.to_csv(\"cleaned_telco_churn.csv\", index=False)\n",
    "print(\"Cleaned dataset saved as 'cleaned_telco_churn.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable Distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Churn', data=df, palette='viridis')\n",
    "plt.title('Distribution of Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features Distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "sns.histplot(df['tenure'], kde=True, ax=axes[0], color='skyblue')\n",
    "axes[0].set_title('Tenure Distribution')\n",
    "\n",
    "sns.histplot(df['MonthlyCharges'], kde=True, ax=axes[1], color='salmon')\n",
    "axes[1].set_title('Monthly Charges Distribution')\n",
    "\n",
    "sns.histplot(df['TotalCharges'], kde=True, ax=axes[2], color='green')\n",
    "axes[2].set_title('Total Charges Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing column names to lowercase for ease\n",
    "df.columns = [c.lower() for c in df.columns]\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn vs Contract Type\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.countplot(x='contract', hue='churn', data=df, palette='pastel')\n",
    "plt.title('Churn Rate by Contract Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix\n",
    "df_corr = df.copy()\n",
    "df_corr['churn'] = df_corr['churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "numeric_df = df_corr.select_dtypes(include=['number'])\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Model Implementation\n",
    "\n",
    "### 2.1 Data Preprocessing\n",
    "- Encoding Categorical Variables\n",
    "- Feature Scaling\n",
    "- Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop Target from features\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn'].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n",
    "# 2. Encoding Categorical Variables\n",
    "# Get dummy variables for categorical features, drop_first to avoid multicollinearity\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# 3. Scaling Numerical Features\n",
    "# Identify numerical cols: tenure, monthlycharges, totalcharges\n",
    "num_cols = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "scaler = StandardScaler()\n",
    "X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "\n",
    "# 4. Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training Shape: {X_train.shape}\")\n",
    "print(f\"Testing Shape: {X_test.shape}\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY SMOTE TO TRAINING DATA\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n",
    "print(\"\\nAfter SMOTE:\", y_train_sm.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision Tree Classifier\n",
    "- Implementation\n",
    "- Hyperparameter Tuning (GridSearchCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Grid Search\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "best_dt = grid_search.best_estimator_\n",
    "print(\"Parameters which are best suited for the Decision Tree:\", grid_search.best_params_)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = best_dt.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(\n",
    "    best_dt,\n",
    "    feature_names=X_train.columns,\n",
    "    class_names=[\"No Churn\", \"Churn\"],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Neural Network Classifier\n",
    "- Implementation using TensorFlow/Keras\n",
    "- Model Architecture: Input -> Dense(ReLU) -> Dropout -> Dense(ReLU) -> Output(Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_nn_model(input_dim, hidden_units_1, hidden_units_2, dropout_rate, learning_rate):\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=(input_dim,)),\n",
    "        Dense(hidden_units_1, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(hidden_units_2, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# Keep the grid compact to make CV practical in notebook runtime.\n",
    "nn_param_grid = {\n",
    "    'hidden_units_1': [32, 64],\n",
    "    'hidden_units_2': [16],\n",
    "    'dropout_rate': [0.1, 0.2],\n",
    "    'learning_rate': [0.001, 0.0005],\n",
    "    'batch_size': [32],\n",
    "    'epochs': [50]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_results = []\n",
    "best_params = None\n",
    "best_cv_accuracy = -np.inf\n",
    "\n",
    "for params in ParameterGrid(nn_param_grid):\n",
    "    fold_accuracies = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train, y_train):\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Apply SMOTE inside each fold to avoid data leakage\n",
    "        X_fold_train_sm, y_fold_train_sm = SMOTE(random_state=42).fit_resample(X_fold_train, y_fold_train)\n",
    "\n",
    "        fold_model = build_nn_model(\n",
    "            input_dim=X_train.shape[1],\n",
    "            hidden_units_1=params['hidden_units_1'],\n",
    "            hidden_units_2=params['hidden_units_2'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "\n",
    "        early_stop = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        fold_model.fit(\n",
    "            X_fold_train_sm,\n",
    "            y_fold_train_sm,\n",
    "            validation_data=(X_fold_val, y_fold_val),\n",
    "            epochs=params['epochs'],\n",
    "            batch_size=params['batch_size'],\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        y_fold_pred = (fold_model.predict(X_fold_val, verbose=0).ravel() > 0.5).astype(int)\n",
    "        fold_accuracies.append(accuracy_score(y_fold_val, y_fold_pred))\n",
    "\n",
    "    mean_acc = float(np.mean(fold_accuracies))\n",
    "    std_acc = float(np.std(fold_accuracies))\n",
    "\n",
    "    cv_results.append({\n",
    "        'params': params,\n",
    "        'mean_cv_accuracy': mean_acc,\n",
    "        'std_cv_accuracy': std_acc\n",
    "    })\n",
    "\n",
    "    print(f\"Params: {params} | Mean CV Accuracy: {mean_acc:.4f} (+/- {std_acc:.4f})\")\n",
    "\n",
    "    if mean_acc > best_cv_accuracy:\n",
    "        best_cv_accuracy = mean_acc\n",
    "        best_params = params\n",
    "\n",
    "print(\"\\nBest NN Hyperparameters:\", best_params)\n",
    "print(f\"Best CV Accuracy: {best_cv_accuracy:.4f}\")\n",
    "\n",
    "# Train final model with best hyperparameters on full SMOTE training set\n",
    "final_early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model = build_nn_model(\n",
    "    input_dim=X_train.shape[1],\n",
    "    hidden_units_1=best_params['hidden_units_1'],\n",
    "    hidden_units_2=best_params['hidden_units_2'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    learning_rate=best_params['learning_rate']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_sm,\n",
    "    y_train_sm,\n",
    "    validation_split=0.1,\n",
    "    epochs=best_params['epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    callbacks=[final_early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "cv_results_df = pd.DataFrame(cv_results).sort_values(by='mean_cv_accuracy', ascending=False).reset_index(drop=True)\n",
    "cv_results_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Training History (Accuracy + Loss)\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "# Accuracy Curve \n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Neural Network Accuracy History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss Curve \n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Neural Network Loss History')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "y_prob_nn = model.predict(X_test, verbose=0).ravel()\n",
    "y_pred_nn = (y_prob_nn > 0.5).astype(int)\n",
    "\n",
    "print(f\"Best CV Accuracy (NN): {best_cv_accuracy:.4f}\")\n",
    "print(f\"Neural Network Test Accuracy: {accuracy_score(y_test, y_pred_nn):.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_nn))\n",
    "\n",
    "# Save best model\n",
    "best_model_path = 'best_nn_model.keras'\n",
    "model.save(best_model_path)\n",
    "print(f\"Best neural network saved to: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFUSION MATRIX - DECISION TREE\n",
    "cm_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix - Decision Tree\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "# CONFUSION MATRIX - NEURAL NETWORK\n",
    "cm_nn = confusion_matrix(y_test, y_pred_nn)\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm_nn, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Confusion Matrix - Neural Network\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Model Comparison (ROC-AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Probabilities\n",
    "y_prob_dt = best_dt.predict_proba(X_test)[:, 1]\n",
    "fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_dt)\n",
    "auc_dt = auc(fpr_dt, tpr_dt)\n",
    "\n",
    "# Neural Network Probabilities\n",
    "if 'y_prob_nn' not in globals():\n",
    "    y_prob_nn = model.predict(X_test, verbose=0).ravel()\n",
    "fpr_nn, tpr_nn, _ = roc_curve(y_test, y_prob_nn)\n",
    "auc_nn = auc(fpr_nn, tpr_nn)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (AUC = {auc_dt:.2f})')\n",
    "plt.plot(fpr_nn, tpr_nn, label=f'Neural Network (AUC = {auc_nn:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Decision Tree Metrics \n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
    "dt_precision = precision_score(y_test, y_pred_dt)\n",
    "dt_recall = recall_score(y_test, y_pred_dt)\n",
    "dt_f1 = f1_score(y_test, y_pred_dt)\n",
    "dt_auc = auc_dt\n",
    "\n",
    "# Neural Network Metrics\n",
    "nn_accuracy = accuracy_score(y_test, y_pred_nn)\n",
    "nn_precision = precision_score(y_test, y_pred_nn)\n",
    "nn_recall = recall_score(y_test, y_pred_nn)\n",
    "nn_f1 = f1_score(y_test, y_pred_nn)\n",
    "nn_auc = auc_nn\n",
    "\n",
    "# Combine into lists for plotting\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC\"]\n",
    "dt_scores = [dt_accuracy, dt_precision, dt_recall, dt_f1, dt_auc]\n",
    "nn_scores = [nn_accuracy, nn_precision, nn_recall, nn_f1, nn_auc]\n",
    "\n",
    "dt_scores, nn_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(metrics))  # number of metrics\n",
    "width = 0.35  # bar width\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.bar(x - width/2, dt_scores, width, label='Decision Tree')\n",
    "plt.bar(x + width/2, nn_scores, width, label='Neural Network')\n",
    "\n",
    "plt.xticks(x, metrics)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Model Performance Comparison (DT vs NN)\")\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}